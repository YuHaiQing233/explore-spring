
**概念**
```text
概念：Redis 是用C语言开发的一个开源的高性能的键值对（key-value）数据库；

特征：
    1. 数据之间没有必然的关联关系；
    2. 高性能（官方提供测试数据，50 个并发执行 100000 个请求,读的速度是 110000 次/s,写的速度是 81000 次/s）；
    3. 多数据类型的支持
        a. 字符串类型：String（类似Java中的String）
        b. 列表类型：List（类似Java中的LinkedList）
        c. 散列类型： Hash（类似Java中的HashMap）
        d. 集合类型： Set（类似Java中的HashSet）
        e. 有序集合类型：Zset (sorted set)（类似Java中的TreeSet）
    4. 支持持久化：可以进行灾难数据恢复；


应用场景：
    1. 为热点数据加速查询（主要场景），热点商品、热点新闻、热点资讯、推广类等高访问量信息等。
    2. 任务队列，比如：秒杀、抢购、购票排队；
    3. 即时信息查询，比如：各类排行榜、各类网站访问统计、公交到站信息、在线人数信息（聊天室、网站）、设备信息等；
    4. 时效性信息控制，比如：验证码控制、投票控制；
    5. 分布式数据共享，比如：分布式集群架构中的session控制；
    6. 消息队列；
    7. 分布式锁；


Redis数据存储格式：
    1. Redis本身是一个Map，其中的所有数据都是采用 key:value 的形式存储；
    2. 数据类型 指的是 存储的数据的类型，也就是value的数据类型，key永远是字符串；
    


```

**String类型**
```text
简介：
    存储的数据：单个数据，最简单的数据存储类型，也是最常用的数据存储类型；
    存储数据的格式：一个存储空间保存一个数据；
    存储内容：通常使用字符串，如果字符串以整数的形式展示，那么可以作为数字操作使用（可以通过CAS来加减数值），但是依然是按照字符串存储的；
    
    
基本操作：
    添加或修改数据：set key value
    获取数据：get key 
    删除数据： del key 
    批量添加数据：mset key value key value ...
    批量获取数据： mget key1 key2 key3 ...
    获取数据字符（value）长度： strlen key 
    追加信息到原始信息后面（如果原始信息存在就追加，否则新建）： append key value

单数据操作 VS 多数据操作:
    1. 单指令（set）添加3条数数据： (set time x 3) + (result time x 3) + (storage time x 3)
    2. 批量添加（mset）3条数据： set time + result time + (storage time x 3)
    结果：添加相同数量的数据，批量操作效率更高，
    注意：同等情况下，多数据操作要比单数据操作执行效率高，但是，如果多数据操作一次发送的数据太多，那么也要进行切分（比如：一次发送 1 亿个数据，实在是太大了，那么就切成每次发送 100 万个）。


数据未获取到：(nil) 等同于 null 。
数据最大存储量：512 MB。
数值计算最大范围（Java 中的 long 的最大值）：9223372036854775807 。


```
```text
第一种string类型数据的扩展操作：

    业务场景：
        MySQL分表时使用多张表存储同类型数据，如果保证主键的唯一性？
    解决方案：
        1. set id 1   新增一个 key为id value为1的值
        2. incr id  =>  id 自增 id = id + 1
        3. incrby id increment => id 自增 id = id + increment
        4. decr id  => id = id - 1
        5. decrby id increment  => id = id - increment
        
    string作为数值操作：
        1. string在Redis内存存储默认就是一个字符串，当遇到增减类操作incr、decr时会转换为数值型进行计算。
        2. Redis所有的操作都是原子性的，采用单线程处理所有业务，命令是一个一个执行的，因此无需考虑并发带来的数据影响。
        
    总结：
        1. Redis用于控制数据库表的主键Id，为数据库主键提供生成策略，保证数据库表的主键唯一。
        2. 此方案适用于所有的关系型数据库，且支持数据库集群


第二种string类型数据的扩展操作：
    业务场景：
        1. 超级女声 启动海选投票，只能通过微信投票，每个微信号每四个小时只能投1票。
        2. 电商商家开启热门商品推荐，热门商品不能一直处于热门，每种商品热门维持3天，3天后自动取消热门。
        3. 新闻网站会出现热点新闻，热点新闻最大的特点就是时效性，如何自动控制热点新闻的时效性。
    
    解决方案：
        1. 设置数据的有效期
            a. setex key seconds value , 将值 value 关联到 key ，并将 key 的过期时间设为 seconds (以秒为单位)。
            b. psetex key milliseconds value, 这个命令和 SETEX 命令相似，但它以毫秒为单位设置 key 的生存时间，而不是像 SETEX 命令那样，以秒为单位。
    
    总结：Redis 控制数据的生命周期，通过数据是否生效来控制业务行为，适用于所有具有时效性限定控制的操作。
```
**string类型应用场景**
```text
业务场景：
    主页高频访问信息显示，例如：新浪微博大 V 主页，显示粉丝数和微博数量。
    
解决方案1：
    在 Redis 中为大 V 用户设定用户信息，以用户主键和属性值作为 key ，后台设定定时刷新策略即可。    
        a. user:id:100100100:fans --->  13097000
        b. user:id:100100100:focuses --->  82
        c. user:id:100100100:blogs --->  11250
    
解决方案2：
    在 Redis 中以 JSON 格式存储大 V 用户信息，定时刷新（也可以使用 hash 类型）。
        a. user:id:100100100 --> {id:100100100,fans:13097000,focuses:82,blogs:11250}
    
    
总结：Redis应用于各种结构型和非结构型高热度数据进行访问加速。      
    
    
数据库中热点数据key命名习惯： 表名:主键名:主键值:字段名  ===>  news:id:20230515:title
    
```

**hash类型**
```text
问题：使用string类型来存储 Java类中的各数据存储：
    1. 如果单个字段存储，那么一个对象的信息更新，出现数据割裂的情况；
    2. 如果将Java类数据保存为JSON，会频繁的修改Redis中的数据；

方案：
    这种情况可以使用hash结构来存储数据

简介：
    新的存储需求：对一系列存储的数据进行编组，方便管理，典型应用就是存储对象信息
    需要的存储结构：一个存储空间保存多个键值对数据。
    hash类型：底层使用hash表结构实现数据存储。
    
    hash存储结构优化：
        a. 如果field数据较少，存储结构优化为类数组结构；
        b. 如果field数据较多，存储结构使用HashMap结构；


hash类型数据的基本操作：
    添加/修改数据：hset key field value  
    获取数据：hget key field
    获取全部数据（获取key下面所有的field）：hgetall key 
    删除数据（支持批量删除field）：hdel key field1 [field2]
    批量添加/修改数据： hmset key field1 value1 field2 value2
    批量获取field值：hmget key field1 field2 field3
    获取哈希表中字段的数量： hlen key
    获取hash表中是否存储指定字段： hexists key field

hash类型数据的扩展操作：
    获取哈希表中所有的字段名：hkeys key 
    获取哈希表中所有的字段值：hvals key 
    设置指定字段的数值自增（整数）： hincrby key field increment
    设置指定字段的数值自增（浮点）： hincrbyfloat key field increment


注意事项：
    1. hash类型下的value只能存储字符串，不能存储其他数据类型，不存在嵌套现象。如果数据没有获取到，对应的值为（nil）.
    2. 每个hash可以存储2^32 - 1 个键值对。
    3. hash类型十分贴近对象的数据存储形式，并且可以灵活的添加删除对象属性。但hash设计初衷并不是为了存储大量对象而设计的，不要滥用，更不要将hash当做对象列表来使用
    4. hgetall 操作可以获取全部的field和value,如果hash内部field过多，遍历整体数据效率就会降低，有可能成为访问瓶颈。

```
**hash类型应用场景**
```text
业务场景一：
    电商网站购物车设计和实现。
    
业务分析：
    1. 仅分析购物车的Redis存储模型
        a. 添加
        b. 浏览
        c. 更改数量
        d. 删除
        e. 清空
    2. 购物车和数据库持久化同步（不讨论）
    3. 购物车和订单的关系（不讨论） 
        a. 提交购物车：读取数据生成订单。
        b. 商家临时价格调整：隶属于订单级别。
    4. 未登录用户购物车信息存储（不讨论）


解决方案：
    1. 以客户Id为key, 每位客户创建一个hash存储结构，来存储对应的购物车信息。
    2. 将商品编号作为field，购买数量作为value进行存储
    3. 添加商品：追加全新的field和value值
    4. 浏览：遍历hash
    5. 更改数量：自增/自减，设置value值
    6. 删除商品：删除商品field
    7. 清空：删除key
    
当前设计仅仅是将数据存储到了Redis中，并没有起到加速的作用，商品信息还需要二次查询数据库，那么该怎么办呢？
    1. 每条购物车中的商品记录保存两条field
    2. field1  key: 商品Id:nums   value: 商品数量
    3. field2  key: 商品Id:info   value: 商品信息JSON

------------------------------------------------------------------------------------------------------------------------

业务场景二：
    双 11 活动日，销售手机充值卡的商家对移动、联通、电信的 30 元、50 元、100 元商品推出抢购活动，每种商品抢购上限 1000 张。

解决方案：
    1. 以商家Id作为key
    2. 将参与抢购的商品Id作为field
    3. 将参与抢购的商品数据作为value
    4. 抢购的时候使用将值的方式控制产品数量

总结：Redis 应用于抢购、限购类、限量发放优惠券、激活码等业务的数据存储设计。

```

**list类型**
```text

简介：
    数据存储需求：存储多个数据，并对数据进入存储空间的顺序进行区分；
    需要的存储结构：一个存储空间可以保存多个数据，且可以通过数据体现进入顺序；
    list类型：保存多个数据，底层使用双向链表存储结构实现的；


list类型数据的基本操作：
    从头部添加数据： lpush key value1 [value2] ...
    从尾部添加数据： rpush key value1 [value2] ...
    通过索引获取列表中的元素： lindex key index 
    获取列表指定范围内的元素: lrange key start stop 
    获取列表长度：llen key 
    从头部获取并移除数据： lpop key 
    从头部获取并移除数据： rpop key 
    

list类型数据的扩展操作：
    规定时间内从头部获取并移除操作：blpop key1 [key2]... timeout
    规定时间内从尾部获取并移除操作：brpop key1 [key2]... timeout
    移除指定数量的数据： lrem key count value 
        a. count > 0 : 从表头开始向表尾搜索，移除与 VALUE 相等的元素，数量为 COUNT 。
        b. count < 0 : 从表尾开始向表头搜索，移除与 VALUE 相等的元素，数量为 COUNT 的绝对值。
        c. count = 0 : 移除表中所有与 VALUE 相等的值。

总结：Redis 应用于具有操作先后顺序的数据控制。


list类型数据操作的注意事项：
    1. list中保存的数据都是string类型的，数据总容量是有限的，最多2^32-1个元素。
    2. list具有索引概念，但是操作数据的时候通常以队列的形式进行入队出队操作，或以入栈的形式进行入栈出栈操作
    3. 获取全部数据，操作结束索引设置为-1
    4. list 可以对数据进行分页操作，通常第一页的信息来自于list,第二页及更多的信息通过数据库的形式来加载 

```

**list类型应用场景**
```text
 业务场景一：
    1. twitter、新浪微博中个人用户的关注列表需要按照用户的关注顺序进行展示，粉丝列表需要将最近关注的粉丝列在前面。
    2. 新闻、资讯类网站如何将最近的新闻或资源按照发生的时间顺序展示？
    3. 企业运营过程中，系统将产生大量的运营数据，如何保证多台服务器操作日志统一顺序输出？
    
 解决方案：
    1. 依赖list的数据具有顺序的特征对信息进行管理；
    2. 使用队列模型解决多路信息汇总合并的问题；
    3. 使用栈模型解决最新消息的问题；   
 
 总结：Redis 可以应用于最新消息的展示。
```

**set类型**
```text

简介：
    新的存储需求：存储大量数据，在查询方面提供更高的效率
    需要的数据结构：能够存储大量的数据，高效的内部存储机制，便于查询
    set类型：和hash存储结构完全相同，仅存储键，不存储值（nil）,并且key是不允许重复

set类型数据的基本操作：
    添加数据：sadd key member1 [member2] ...
    获取全部的数据：smembers key 
    删除数据： srem key member1 [member2] ...
    获取集合数据总量：scard key 
    判断集合中是否包含指定数据：sismember key member
    
set类型数据的拓展操作：
    随机获取集合中指定数量的数据：srandmember key [count]
    随机获取集合中的某个数据并将该数据移除集合： spop key [count]

总结：Redis 应用于随机推荐类信息检索，例如：热点歌单推荐、热点新闻推荐、热卖旅游线路、应用 APP 推荐，大 V 推荐等等。


set类型数据的拓展操作：
    计算集合间的交集部分：sinter key1 [key2] ...
    计算集合间的并集部分：sunion key1 [key2] ...
    计算集合间的差集部分：sdiff key1 [key2] ...
    
    计算集合间的交集并存储到指定集合：sinterstore destination key1 [key2]
    计算集合间的并集并存储到指定集合：sunionstore destination key1 [key2]
    计算集合间的差集并存储到指定集合：sdiffstore destination key1 [key2]
    
    将指定数据从原始集合中移动到目标集合中：smove source destination member 


set类型操作的注意事项：
    1. set类型不允许数据重复，如果添加的数据在set中已经存在，将只保留一份；
    2. set虽然和hash存储结构相同，但是无法启用hash中的存储值的空间；

```
**set类型应用场景**
```text

业务场景一：
    集团公司共有 12000 名员工，内部 OA 系统中具有 700 多个角色，3000 多个业务操作，23000 多种数据，每位员工具有一个或多个角色，如何快速进行业务操作的权限校验？

解决方案：
    1. 依赖set集合数据不重复的特征，依赖set集合hash存储结构特征完成数据过滤和快速查询
    2. 根据用户Id获取用户所有角色
    3. 根据用户所有角色获取用户所有操作权限放入到set集合
    4. 根据用户所有角色获取用户所有数据权限放入到set集合
总结：Redis 引用于同类型不重复数据的合并操作。


业务场景二：
    1. 公司对旗下新的网站做推广，统计网站的 PV（访问量），UV（独立访客）、IP（独立 IP）。
    2. PV：网站被访问次数，可以通过刷新页面提高访问量。
    3. UV：网站被不同用户访问的次数，可以通过 cookie 统计访问量，相同用户切换 IP 地址，UV 不变。
    4. 网站被不同 IP 地址访问的次数，可以通过 IP 地址统计访问量，相同 IP 不同用户访问，IP 不变。

解决方案：
    1. 利用 set 集合的数据去重特征，记录各种访问数据。
    2. 建立 string 类型数据，利用 Incr 统计日访问量（PV）。
    3. 建立 set 模型，记录不同 cookie 数量（UV）。
    4. 建立 set 模型，记录不同 IP 数量（IP）。

其他场景：
    1. 每位用户首次使用今日头条时会设置 3 项爱好的内容，但是后期为了增加用户的活跃度、兴趣点，必须让用户对其他信息类别产生兴趣，增加客户的留存度，如何实现？ 【随机取值】
    2. 脉脉为了促进用户间的交流，保障业务成单率的提升，需要让每位用户拥有大量的好友，事实上职场新人不具有更多的职场好友，如何快速的为用户积累更多的好友？
    3. 新浪微博为了增加用户热度，提高用户留存性，需要微博用户在关注更多的人，以此获取更多的信息或热门话题，如何提高用户关注他人的总量？
    4. QQ 新用户入网年龄越来越低，这些用户的朋友圈交际圈非常小，往往集中在一所学校甚至一个班级中，如何帮助用户快速积累好友，给用户带来更多的活跃度？
    5. 微信公众号是微信信息流通的渠道之一，增加用户关注的公众号称为提高用户活跃度的一种方式，如何帮助用户积累更多关注的公众号？
    6. 美团外卖为了提升成单量，必须帮助用户挖掘美食需求，如何推荐给用户最适合自己的美食？

```

**zset类型 (sorted set)**
```text

简介：
    新的存储需求：数据排序有利于数据的有效展示，需要提供一种可以根据自身特征进行排序的方式；
    需要的存储结构：新的存储结构，可以保证可排序的数据；
    sorted_set: 在set的存储结构的基础上添加可排序字段
    
sorted_set类型数据的基本操作：
    添加数据：zadd key score1 member1 [score2 member2] ...
    通过索引区间返回有序集合指定区间内的成员从低到高：zrange key start stop [withscores]
    返回有序集中指定区间内的成员，通过索引，分数从高到低: zrevrange key start stop [withscore]
    删除数据： zrem key member [member1 member2] ...
    
    按条件获取数据（ASC）：zrangebyscore key min max [withscore] [limit offset count]
    按条件获取数据（DESC）： zrevrangebyscore key min max [withscore] [limit offset count]
    按条件删除（rank）: zremrangebyrank key start stop 
    按条件删除（score） zremrangebyscore key min max 
    
    获取集合数据总量：zcard key 
    获取集合数据总量 zcount key min max 
    
    交集集合：zinterstore destination numkeys key1 [key2]...
    并集集合：zunionstore destination numkeys key1 [key2]...
    

sorted_set类型数据的拓展操作：

    业务场景：
        1. 票选江苏十大杰出青年，各类综艺选秀海选投票。
        2. 各类资源网站 TOP 10（电影、歌曲、文档、电商、游戏等）。
        3. 聊天室活跃度统计。
        4. 游戏好友亲密度。
    业务分析：
        为所有参与排序的资源建立排序依据。
    解决方案：
        获取数据排名(ASC)：zrank key member 
        获取数据排名(DESC)：zrevrank key member 
        
        获取分数值：zscore key member
        分数值自增：zincrby key increment member


sorted_set类型数据操作的注意事项：
    1. score 保存的数据存储空间是 64 位，如果是整数范围是 -9007199254740992 ~ 9007199254740992 。
    2. score 保存的数据也可以是一个双精度的 double 值，基于双精度浮点数的特征，可能会丢失精度，使用的时候需要慎重。
    3. sorted_set 底层存储还是基于 set  结构的，因此数据不能重复，如果重复添加相同的数据，score 值将被反复覆盖，保留最后一次修改的结果。

```
**sorted set 类型应用场景**
```text

业务场景：
    1. 基础服务 + 增值服务类网站会设定各位会员的试用，让用户充分体验会员优势。例如：观影试用 VIP ，游戏 VIP 体验，云盘下载体验 VIP ，数据查看体验 VIP 。当 VIP 体验到期后，如何有效管理此类信息？即使对于正式的 VIP 用户，也应该存在对应的管理方式。
    2. 网站会定期开启投票、讨论、限时进行，逾期作废，如何有效管理此类过期信息？
    
解决方案：
    1. 对于基于时间线限定的任务处理，将处理时间记录为 score 值，利用排序功能区分处理的先后顺序。
    2. 记录下一个要处理的时间，当到期后处理对应任务，移除 Redis 中的记录，并记录下一个要处理的时间。
    3. 当新任务加入时，判断并更新当前下一个要处理的任务时间。
    4. 为提升 sorted_set 的性能，通常将任务根据特征存储若干个 sorted_set 。例如：1 小时内、1 天内、周内、月内、季内、年度等，操作时逐级提升，将即时操作的若干个任务纳入到 1 小时内处理的任务队列中。


业务场景二：
    当任务或者消息待处理，形成了任务队列或消息队列时，对于高优先级的任务要保障对其优先处理，如何实现任务权重管理？ 

解决方案：
    对于带有权重的任务，优先处理权重高的任务，采用 score 记录权重即可。

```

**Redis持久化**
```text

持久化简介：
    1. 什么是持久化？
        a. 利用永久性的存储介质（如：硬盘等）将数据进行保存，在特定的时间，将保存的数据进行恢复的工作机制称为持久化。
    2. 为什么要进行持久化？
        a. 防止数据的意外丢失，确保数据安全
    3. 持久化的过程中保存什么？
        a. 将当前数据状态进行保存（类似于快照形式），存储数据结果，存储格式简单，关注点在于数据 （RDB）
        b. 将数据的操作过程进行保存（类似于日志形式），存储操作过程，存储格式复杂，关注点在于数据操作（AOF）
```

**持久化之RDB**
```text

RDB 启动方式 -- save 指令

    save指令：
        手动执行save指令后，当前Redis中的数据会进行一次快照，但是持久化的过程中（Redis服务将会被阻塞）
        
    工作原理：
        1. 单线程任务执行序列 （set --> set -->  save  --> get ）；
        
    注意：save 指令的执行会阻塞当前 Redis 服务器，直到当前 RDB 过程完成为止，有可能会造成长时间阻塞，线上环境不建议使用


    配置（redis.conf）：
        save second changes   --->  满足限定时间内 key 的变化数量达到指定数量就进行持久化操作。
        second:  监控时间范围。
        changes: 监控 key 的变化量。
    例子： save 900 1  ---> 900秒内只要有一个key发生变化，就触发RDB save 持久化


RDB 启动方式 -- save 指令工作原理
    
    如何解决RDB持久化效率过低的问题：
        问：数据量过大，单线程执行方式造成效率过低如何处理？ 
        答：后台执行。 
        
    作用：手动启动后台保存操作，但是不是立即执行。
     
    工作原理：
        1. 发送指令（bgsave）
        2. 调用 fork函数生成子进程
        3. 创建RDB文件
        4. 返回消息
        
    注意：bgsave 指令是针对 save 阻塞问题做的优化。Redis 内部所有涉及到 RDB 操作都可以采用 bgsave 指令的方式，save 指令可以放弃使用 。

RDB 三种启动方式对比
    1. save 指令
        a. 读写： 同步
        b. 阻塞客户端指令： 是
        c. 额外内存消耗：否
        d. 启动新进程： 否
    2. bgsave 指令
        a. 读写： 异步
        b. 阻塞客户端指令： 否
        c. 额外内存消耗：是
        d. 启动新进程： 是
    3. save 配置
        a. 读写： 异步
        b. 阻塞客户端指令： 否
        c. 额外内存消耗：是
        d. 启动新进程： 是

RDB持久化的优点与缺点：
    优点：
        1. RDB是一个紧凑压缩的二进制，存储效率高；
        2. RDB内存存储的是Redis在某个时间点的数据快照，非常适合用于数据备份，全量复制等场景。
        3. RDB恢复数据的速度要比AOP快很多。
        4. 应用：服务器中每 x 小时执行 bgsave 备份，并将 RDB 文件拷贝到远程机器中，用于灾难恢复。
        
    缺点：
        1. RDB方式无论是执行指令还是利用配置，无法做到实时持久化，具有较大的可能性丢失数据。
        2. bgsave指令每次运行要执行fork操作创建子进程，要牺牲一些性能。
        3. Redis的众多版本中未进行RDB文件格式的版本统一，有可能出现各版本服务之间数据格式无法兼容现象。


```

**持久化之AOF**
```text

RDB 存储的弊端:
    1. 存储数据量较大，效率较低：基于快照思想，每次读写都是全部数据，当数据量过大的时候，效率非常低。
    2. 大数据量下的IO性能较低。
    3. 基于fork创建子进程，内存产生额外消耗。
    4. 如果不是实时做快照，那么宕机会带来数据丢失的风险。
    
解决思路：
    1. 不写全数据，仅记录部分数据。
    2. 改记录数据为记录操作过程。
    3. 对所有的操作均进行记录，排查丢失数据的风险。


AOF简介：
    1. AOF(append only file)持久化：以独立日志的方式记录每次命令，重启时再重新执行AOF文件中命令达到恢复数据的目的，和RDB相比 可以描述为 改记录数据为记录数据产生的过程。
    2. AOF的主要作用是解决了数据持久化的实时性，目前已经是Redis持久化的主流方式。


AOF写数据的三种策略：
    1. always（每次）：每次写操作均同步到AOF文件中，数据零误差，性能较低（大数据量下时，系统资源被IO大量占用，那么业务系统的性能将会有所影响），不建议使用
    2. everysec（每秒）：
        a. 每秒将缓存区中的指令同步到AOF文件中，数据准确性高，性能较高
        b. 在系统突然宕机的情况下丢失1秒内的数据。
        c. 建议使用，也是系统默认配置
    3. no（系统控制）：有操作系统控制每次同步到AOF文件的周期，整体过程不可控，不建议使用


AOF重写：
    连续执行对同一个key的写操作，随着命令不断写入 AOF，文件会变得越来越大，为了解决这个问题，Redis 引入了 AOF 重写机制来压缩文件体积。AOF 文件重写是将 Redis 进程内的数据转换为写命令同步到新 AOF 文件的过程。简单来说，就是将对统一数据的若干条命令结果转换成最终结果数据对应的指令进行记录。
    
AOF重写的作用：
    1. 降低磁盘占用量，提高磁盘利用率。
    2. 提高持久化效率，降低持久化写时间，提高IO性能。
    3. 降低数据恢复用时，提高数据恢复效率。
    
AOF重写规则：
    1. 进程内已超时的数据不再写入文件。
    2. 忽略无效指令，重写时使用进程内的数据直接生成，这样新的AOF文件只保存最终数据的写入命令
    3. 对同一数据的多条命令合并为一条命令。（为了防止数据量过大造成客户端缓冲区溢出，每条指令最多写入64个元素）

AOF重写方式：
    1. 发送指令：bgrewriteaof
    2. 调用fork函数生成子进程
    3. 重写AOF文件
    4. 返回消息
    
AOF自动重写：
    1. auto-aof-rewrite-min-size size  设置自动重写的下限
    2. auto-aof-rewrite-percentage percentage 设置自动重写的比率  （aof_current_size - aof_base_size） / aof_base_size >= auto-aof-rewrite-percentage


RDB 与 AOF的区别
    RDB：
        1. 占用存储空间： 小（数据级：压缩）
        2. 存储速度： 慢
        3. 恢复速度： 快
        4. 数据安全性： 会丢失数据
        5. 资源消耗： 高/重量级
        6. 启动优先级： 低
    AOF：
        1. 占用存储空间： 大（指令级：重写）
        2. 存储速度： 快
        3. 恢复速度： 慢
        4. 数据安全性： 依据策略决定
        5. 资源消耗： 低/轻量级
        6. 启动优先级： 高

RDB和AOF选择：
    1. 对数据非常敏感，建议使用默认的 AOF 持久化方案。
        a. AOF 持久化策略使用 everysec，每秒钟 fsync 一次。该策略 Redis 依然可以保持很好的处理性能，当出现问题的时候，最多丢失 0 ~ 1 秒内的数据。
        b. 注意：由于 AOF 文件存储体积较大，且恢复速度较慢。
    2. 数据呈现阶段有效性，建议使用 RDB 持久化方案。 
        a. 数据可以良好的做到阶段内无丢失（该阶段是开发人员或运维人员手动维护的），且恢复速度较快，阶段性数据恢复通常采用 RDB 方案。
        b. 注意：利用 RDB 实现紧凑的数据持久化会使 Redis 性能下降的非常厉害（Redis 中的数据越多，频繁的进行 RDB 持久化，将会使得性能下降的比较厉害）。
    
    总结：
        1. RDB 和 AOF 的选择实际上是做一种权衡，各有利弊。
        2. 如果不能承受数分钟以内的数据丢失，对业务数据非常敏感，选用 AOF 。
        3. 如果能承受数分钟以内的数据丢失，且追求大数据集的恢复速度，选用 RDB 。
        4. 灾难恢复选用 RDB 。
        5. 双保险策略，同时开启 RDB 和 AOF ，重启后，Redis 优先使用 AOF 来恢复数据，降低数据丢失的量。

Redis持久化场景：
    1. Redis 应用于抢购、限购类、限量发放优惠券、激活码等业务的数据存储设计。
    2. Redis 应用于具有操作先后顺序的数据控制。
    3. Redis 应用于最新消息展示。
    4. Redis 应用于基于黑白名单设定的服务控制。
    5. Redis 应用于计数器组合排序功能对应的排名。

```

**Redis事务**
```text

事务简介:
    1. Redis 事务就是一个命令执行的队列，将一系列预定义的命令包装成一个整体（一个队列）。当执行的时候，一次性按照添加的顺序依次执行，中间不会被打断或者干扰。
    2. 简而言之，Redis 事务就是一个队列中，一次性、顺序性、排他性的执行一系列命令。
    
事务的基本操作：
    1. multi : 开启事务 （开启事务：设定事务的开启位置，此指令执行后，后续的所有指令均加入到事务中）
    2. exec : 执行事务  （执行事务：设置事务的结束位置，同时结束事务。和 multi 成对出现，成对使用）
        注意：加入事务的命令暂时进入到任务队列中，并没有立即执行，只有执行 exec 命令才开始执行。
    3. discard : 取消事务 （取消事务：终止当前事务的定义，发生在 multi 之后， exec 之前）


事务注意事项：
    1. 定义事务的过程中，命令格式输入错误怎么办？
        a. 语法错误：指的是命令书写错误。
        b. 处理结果：如果定义的事务中所包含的命令存在语法错误，整体事务所有命令均不执行，包括那些语法正确的命令。 
    
    2. 定义事务的过程中，命令执行出现错误怎么办？
        a. 运行错误：指的是命令格式正确，但是无法正确的执行。如：对 list 进行 incr 操作。
        b. 处理结果：能够正确运行的命令会执行，运行错误的命令不会被执行。
    
```

**Redis 锁**
```text

业务场景：
    天猫双 11 热卖过程中，对已经售罄的货物追加补货，4 个业务员都有权限进行补货。补货的操作可能是一系列的操作，涉及到多个连续操作，如何保证不会重复操作？
    
业务分析：
    1. 多个客户端可能同时操作同一组数据，并且该数据一旦被操作修改后，将不适用于继续操作。
    2. 在操作之前锁定要操作的数据，一旦发生变化，终止当前操作。

解决方案：
    1. 对key添加监视锁，在执行exec前如果key发生了变化，终止事务执行：
        a. 对指定key添加监视锁： watch key1 [key2] ....
        b. 取消对所有key的监视： unwatch
```

**Redis 分布式锁**
```text

业务场景：
    天猫双 11 热卖过程中，对已经售罄的货物追加补货，且补货完成。客户购买热情高涨，3 秒内将所有商品购买完毕。本次补货已经将库存全部清空，如何避免最后一件商品不被多人同时购买（超卖问题）？ 
    
业务分析：
    1. 使用 watch 监控一个 key 有没有改变不能解决问题（商品的数量是不停的变化，难道一个人购买了，其他人的订单取消掉？），此处要监控的是具体数据。
    2. 虽然 Redis 是单线程的，但是多个客户端对同一数据同时进行操作时，如何避免不被同时修改？

解决方案：
    1. 使用 setnx 设置一个公共锁：
        a. 利用 setnx 命令的返回值特征，有值则返回设置失败，没有值则返回设置成功。  
            i:  对于返回设置成功的，拥有控制权，进行下一步的具体业务操作。
            ii: 对于返回设置失败的，不具有控制权，排队或者等待。
        b. 操作完毕后通过 del 操作释放锁。 

分布式锁出现死锁情况：
    需要给分布式锁添加过期时间

```

**Redis 删除策略**
```text

过期数据：
    1. Redis中的数据特征
        a. Redis 是一种内存级别的数据库，所有的数据均存放在内存中，内存中的数据可以通过 ttl 指令获取其状态。
            i:   xx：具有时效性的数据。
            ii:  -1：永久有效的数据。
            iii: -2：已经过期的数据 或被删除的数据或者未定义的数据。
        b. 删除策略就是针对已经过期的数据的处理策略，已经过期的数据真的立即删除吗？其实未必，Redis 中有很多种删除策略，是分情况的，在不同的场景下使用不同的删除方式会有不同的效果。

    2. 时效性数据的存储结构
        a. 在 Redis 中，如何给数据设置它的失效周期？数据的时效在 Redis 中是如何存储的？
            i: setex expire key (过期时间：秒)
            ii: setex expireat key (过期时间：秒时间戳)
            iii: setex pexpire key  (过期时间：毫秒)
            iiii: setex pexireat key (过期时间：毫秒时间错)
            
        b. 过期数据是一块独立的存储空间，是 hash 结构，field 是内存地址，value 是过期时间，保存了所有 key 的过期描述，在最终进行过期处理的时候，对该空间的数据进行检测，当时间到期之后，通过 field 找到对应的该内存地址的数据，然后进行相关的操作。


数据删除策略：
    1. 数据删除策略的目标
        a. 在内存占用和 CPU 占用之间寻找一种平衡，顾此失彼都会造成整体 Redis 性能的下降，甚至引发服务器宕机或内存泄露。
    2. 数据删除策略的分类
        a. 定时删除
            1) 创建一个定时器，当 key 设置有过期时间，且过期时间到达时，定时器立即执行对键的删除操作。
            2) 优点：节约内存，到时就删除，快速释放掉不必要的内存占用。
            3) 缺点：CPU 压力很大，无论 CPU 此时负载量多高，均占用 CPU，会影响 Redis 服务器响应时间和指令吞吐量。
            4) 总结：用处理器的性能换取存储空间（拿时间换空间）。
        b. 惰性删除
            1) 数据到达过期时间，不做处理，等下次访问该数据的时候
                i:  如果没有过期，返回数据。
                ii: 如果已经过期，删除数据，返回不存在。
            2) 优点：节约 CPU 性能，发现必须删除的时候才删除。
            3) 缺点：内存压力很大，出现长期占用内存的数据。
            4) 总结：用存储空间换取处理器性能（拿空间换时间）。
        c. 周期删除
            1) 定时删除和惰性删除这两种方案都是走的极端，那有没有折中方案？ 
            2) Redis 的周期删除方案：
                i: Redis 启动服务器初始化时，读取配置 server.hz 的值，默认为 10 。
                ii: 每秒钟执行 server.hz 次 serverCron() --> databasesCron() --> activeExpireCycle() 。
                iii: activeExpireCycle() 对每个 expires[*] 逐个进行检测，每次执行 250 ms/ server.hz。
                iiii: 对某个 expires[*] 检测的时候，随机挑选 W 个 key 检测：
                    [1]: 如果 key 超时，删除 key 。
                    [2]: 如果一轮中删除的 key 的数量 > W * 25 % ，循环该过程。
                    [3]: 如果一轮中删除的 key 的数量 <= W * 25 % ，检查下一个 expires[*]，0 ~15 循环。
                    [4]: W 取值 = ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 属性值。
                iiiii: 参数 current_db 用于记录 activeExpireCycle()  进入哪个  expires[*] 执行。
                iiiiii: 如果 activeExpireCycle() 执行时间到期，下次从 current_db 继续向下执行。
                
    Redis 内部使用的是 惰性删除 和 周期删除 。
    
    
    
逐出算法：
    1. 概述： 
        a. Redis 使用内存存储数据，在执行每一条命令前，会调用 freeMemoryIfNeeded() 检测内存是否充足。如果内存不满足新加入数据的最低存储要求，Redis 要临时删除一些数据为当前指令清理存储空间，清理数据的策略称为逐出算法。
        b. 注意：逐出数据的过程不是 100% 能够清理出足够的可使用的内存空间，如果不成功则反复执行。当对所有数据尝试完毕后，如果不能达到内存请求的要求，将出现错误信息。


    2. 影响输出逐出的相关配置
        a. 最大可使用内存：占用物理内存的比例，默认为 0 ，表示不限制。生产环境中根据需求设定，通常设置为 50 % 以上。 [maxmemory]
        b. 每次选取待删除数据的个数：选取数据的时候并不会全库扫描，导致严重的性能消耗，降低读写性能。因此采用随机获取数据的方式作为待检测删除数据
        c. 逐出算法策略：达到最大内存后，对被挑选出来的数据进行逐出算法

```

**Redis 集群**
```text

1. 主从复制

2. 哨兵模式

3. 集群

```

**企业级解决方案**
```text

缓存处理流程：
    1. 前台请求，后台先从缓存中读取数据，如果取到直接返回；如果取不到就从数据库中读取，如果数据库中有，就将数据更新到缓存中，同时返回结果；如果数据库中也没有，直接返回空结果。
    
    
缓存预热：
    1. 问题现象
        a. Redis服务启动后迅速宕机
        
    2. 问题排查
        a. 请求数量较高。
        b. 主从之间数据吞吐量较大，数据同步操作频度较高。
        
    3. 解决方案
        a. 前置准备工作
            1> 日常例行统计数据访问记录，统计访问频度较高的热点数据。
            2> 利用LRU数据删除策略，构建数据留存队列，例如storm和kafka配合。
            
        b. 准备工作
            1> 将统计结果中的数据分类，根据级别，Redis 优先加载级别较高的热点数据。
            2> 利用分布式多服务器同时进行数据读取，提高数据加载过程。
            
        c. 实施
            1> 使用脚本程序固定数据预热过程。
            2> 如果条件允许，使用了 CDN（内容分发网络），效果会更好。
        
    4. 总结


缓存雪崩：
    1. 问题现象
        a. 系统平稳运行过程中，忽然数据库的连接量增加，应用服务器无法及时处理请求，大量 408 、500 错误页面出现，导致客户反复刷新页面获取数据，进而引起数据库崩溃、应用服务器崩溃，重启应用服务器无效，Redis 服务器崩溃，Redis 集群崩溃，重启数据库后再次被瞬间流量放倒。
        b. 大量缓存同时失效，导致大量请求到数据库，数据库并不像Redis能处理大量请求，由缓存雪崩导致的请求激增必须会导致数据库所在宕机，这样势必会影响业务系统，所以如果发生缓存雪崩，对于业务系统肯定是致命的。
        
    2. 问题排查
        a. 在一个较短的时间内，缓存内大量的 key 同时过期
            1> 此周期内请求访问过期的数据，Redis 没有命中，Redis 向数据库获取数据 
            2> 数据库同时受到大量的请求无法及时处理，Redis 大量请求被积压，开始出现超时现象，数据库流量激增，数据库崩溃。
            3> 数据库重启后依然面对缓存中没有数据可用，进而导致 Redis 服务器资源被严重占用，Redis 服务器崩溃，Redis 集群呈现崩塌，集群瓦解。
            4> 应用服务器无法及时获取数据响应请求，来自客户端的请求越来越多，应用服务器崩溃。
            5> 应用服务器、Redis、数据库全部重启，效果不理想。
        
        b. 总而言之：短时间范围内，大量key集中过期 。
        
    3. 解决方案（道）
        a. 更多的页面静态化处理，比如：前端进行节流和防抖动处理。
        b. 构建多级缓存架构：Nginx 缓存 + Redis 缓存 + Ehcache 缓存。
        c. 检测 MySQL 严重耗时业务进行优化:  对数据库的瓶颈排查：超时查询、耗时较高的业务等。
        d.  灾难预警机制,  监控 Redis 服务器的性能指标 
            1> CPU 占用、CPU 使用率。
            2> 内存容量。
            3> 查询平均响应时间。
            4> 线程数。
        e. 限流、降级：短时间范围内牺牲一些客户体验，限制一部分请求访问，降低应用服务器压力，等到业务低速运转后再逐步放开访问。

    4. 解决方案（术）
        a. Redis 的逐出算法策略 volatile-lru 和 volatile-lfu 切换。
        b. 数据有效期调整
            1> 根据业务数据有效期进行分类错峰：A 类 90 分钟，B 类 80 分钟，C 类 70 分钟。
            2> 过期时间使用固定时间 + 随机值的形式，避免发生 key 集中到期的现象。
        c. 超热数据使用永久 key
        d. 定期维护（自动 + 人工）：对即将过期数据进行访问量分析，确认是否延时，配合访问量统计，做热点数据的延时。
        e. 使用锁或队列（慎用，效率低）：用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。不适用高并发情况。
        
    总结： 缓存雪崩就是瞬间过期数据量太大，导致对数据库服务器造成压力，如果能够有效避免过期时间集中，可以有效解决雪崩现象的出现，配合其他策略一起使用，并监控服务器的运行数据，根据运行记录做快速调整。
    
    

缓存击穿：
    1. 问题现象
        a. 系统平稳运行过程中，数据库连接量瞬间激增，Redis 服务器无大量 key 过期，Redis 内存平稳、无波动，Redis 服务器 CPU 正常，但是，数据库崩溃。
        
    2. 问题排查
        a. Redis 中某个 key 过期，这个 key 的访问量巨大，多个请求从服务器直接压到 Redis 后，都没有命中，Redis 在短时间内发起了大量对数据库同一数据的访问。
        b. 总而言之：单个 key 高热数据，key 过期 。
        
    3. 解决方案（术）    
        a. 预先设定热门数据
            1> 以电商为例，每个商家根据店铺等级，指定若干款主打商品，在购物节期间，加大此类信息 key 的过期时长。
            2> 注意：购物节不仅仅指当天，以及后续的若干天，访问峰值呈现逐渐降低的趋势。
        b. 现场调整：监控访问量，对自然流量激增的数据延长过期时间或设置为永久 key 。
        c. 后台刷新数据：启动定时任务，高峰期来了之前，刷新数据有效期，确保不丢失。
        d. 二级缓存：设置不同的失效时间，保证不会被同时淘汰。
        e. 加锁：分布式锁，防止被击穿，需要注意性能瓶颈，慎重。
    
    4. 总结：
        a. 缓存击穿是单个高热数据过期的瞬间，数据访问量较大，没有命中 Redis 后，发起了大量对同一数据的数据库访问，导致对数据库服务造成压力。
        b. 应对策略应该在业务数据分析和预防方面进行，配合运行监控测试号和即时调整策略，毕竟单个 key 的过期监控难度较高，配合雪崩处理策略即可。



缓存穿透:
    1. 问题现象
        a. 系统平稳运行过程中，应用服务器流量随时间增量较大，Redis 服务器命中率随时间逐步降低，Redis 内存平稳、内存无压力，Redis 服务器 CPU 占用激增，数据库服务器压力激增，数据库崩溃。
        
    2. 问题排查
        a. Redis 中大面积出现没有命中。
        b. 出现非正常的 URL 访问。
    
    3. 问题分析
        a. 获取的数据在数据库中不存在，数据库没有查询到对应的数据，Redis 获取到 null 数据没有进行持久化，直接返回（黑客攻击服务器）。
        
    4. 解决方案
        a. 缓存 null ：对查询结果为 null 的数据进行缓存（长期使用，定期清理），设定短时限，如：30 ~ 60 秒，最高 5 分钟。
        b. 白名单策略：
            1> 提前预热各种分类数据 id 对应的 bitmaps ，id 作为 bitmaps 的 offset，相当于设置了数据白名单。当加载正常数据时，放行；加载异常数据的时候直接拦截（效率偏低）。
            2> 使用布隆过滤器。
        c. 实时监控
            1> 实时监控 Redis 命中率（业务正常范围内，通常会有一个波动值）和 null 数据的占比
        d. key 加密：问题出现后，临时启动防灾业务 key ，对 key 进行业务层传输加密服务，设定校验程序，过来的 key 检测，例如：每天随机分配 60 个加密串，挑选 2 ~ 3 个，混淆到页面数据 id 中，发现访问 key 不满足规则，驳回数据访问。
        
    5. 总结
        a. 缓存穿透访问了一个不存在的数据，跳过了合法数据的 Redis 数据缓存阶段，每次访问数据库，都会对数据库造成压力。
        b. 通常此类数据刚出现的时候是一个较低的值，慢慢会提升，当出现此类情况时，及时报警，应对策略在临时预案防范方面多做文章。
        b. 无论黑名单还是白名单，都会对整体系统造成压力，警报解除后尽快移除。

```